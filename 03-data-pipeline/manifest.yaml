name: data-pipeline
version: "2.0.0"
description: "ETL pipeline with LLM-powered data enrichment, validation, and error handling"

graphs:
  - name: etl_pipeline
    entry_node: extract
    nodes:
      # Extract data from source
      - id: extract
        kind: task
        label: "Extract Data"
        config:
          action: "extract"
          sources:
            - type: csv
              path: "{input_path}"
      
      # LLM-powered enrichment
      - id: enrich
        kind: router
        label: "LLM Data Enrichment"
        router_ref: enrichment_router
      
      # Schema validation (simplified - validates JSON structure)
      - id: validate
        kind: task
        label: "Schema Validator"
        config:
          action: "validate_json"
          required_fields: ["sentiment", "entities", "category", "confidence"]
      
      # Handle valid records
      - id: load
        kind: task
        label: "Load to Target"
        config:
          action: "load"
          targets:
            - type: json
              path: "{output_path}"
      
      # Handle invalid records
      - id: handle_invalid
        kind: task
        label: "Handle Invalid Records"
        config:
          action: "log_and_skip"
          output: "invalid_records.json"
          notify: true
      
      # Error recovery
      - id: handle_error
        kind: task
        label: "Error Recovery"
        config:
          action: "retry_or_skip"
          max_retries: 3
      
      # Pipeline completion logging
      - id: pipeline_complete
        kind: task
        label: "Pipeline Complete"
        config:
          action: "log_summary"
          metrics: true
    
    edges:
      # Extract → Enrich
      - from_node: extract
        to_node: enrich
      
      # Enrich → Validate (enrichment always succeeds, router returns enriched data)
      - from_node: enrich
        to_node: validate
      
      # Validate → Load (always load for now, validation is pass-through)
      - from_node: validate
        to_node: load
      
      # Load → Complete
      - from_node: load
        to_node: pipeline_complete
      
      # Handle Invalid → Complete
      - from_node: handle_invalid
        to_node: pipeline_complete
      
      # Error handling (from any node)
      - from_node: extract
        to_node: handle_error
        condition:
          trigger: error
      
      - from_node: enrich
        to_node: handle_error
        condition:
          trigger: error
      
      - from_node: validate
        to_node: handle_error
        condition:
          trigger: error

routers:
  - name: enrichment_router
    strategy: llm
    system_message: |
      You are a data enrichment AI. Analyze the input record and extract structured information.
      
      Extract:
      - Sentiment: positive, negative, or neutral
      - Entities: list of people, products, locations mentioned (JSON array)
      - Category: support, feedback, inquiry, or other
      - Confidence: 0.0 to 1.0
      
      Return ONLY valid JSON with these fields:
      {
        "sentiment": "positive|negative|neutral",
        "entities": ["entity1", "entity2"],
        "category": "support|feedback|inquiry|other",
        "confidence": 0.95
      }
      
      No explanations, no markdown, just the JSON object.
    default_model: "ollama://qwen3:8b"

tools: []

policies: []

